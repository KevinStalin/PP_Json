{"paper_id": "0b0ac438cfc332c11bae15ca2673a49141592484", "metadata": {"title": "A Deep Learning and Grad-CAM based Color Visualization Approach for Fast Detection of COVID-19 Cases using Chest X-ray and CT-Scan Images Journal Pre-proof A Deep Learning and Grad-CAM based Color Visualization Approach for Fast Detection of COVID-19 Cases using Chest X-ray and CT-Scan Images A Deep Learning and Grad-CAM based Color Visualization Approach for Fast Detection of COVID-19 Cases using Chest X-ray and CT-Scan Images", "authors": [{"first": "Harsh", "middle": [], "last": "Panwar", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jaypee University of Information Technology", "location": {"postCode": "173 234", "settlement": "Waknaghat, Solan", "region": "HP", "country": "India"}}, "email": "harshpanwar@ieee.org"}, {"first": "P", "middle": ["K"], "last": "Gupta", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jaypee University of Information Technology", "location": {"postCode": "173 234", "settlement": "Waknaghat, Solan", "region": "HP", "country": "India"}}, "email": "pkgupta@ieee.org"}, {"first": "Mohammad", "middle": ["Khubeb"], "last": "Siddiqui", "suffix": "", "affiliation": {}, "email": ""}, {"first": "Ruben", "middle": [], "last": "Morales-Menendez", "suffix": "", "affiliation": {"laboratory": "", "institution": "Tecnologico de Monterrey", "location": {"settlement": "Monterrey", "region": "N.L", "country": "Mexico"}}, "email": ""}, {"first": "Prakhar", "middle": [], "last": "Bhardwaj", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jaypee University of Information Technology", "location": {"postCode": "173 234", "settlement": "Waknaghat, Solan", "region": "HP", "country": "India"}}, "email": "prakharbhardwaj784@gmail.com"}, {"first": "Vaishnavi", "middle": [], "last": "Singh", "suffix": "", "affiliation": {"laboratory": "", "institution": "Jaypee University of Information Technology", "location": {"postCode": "173 234", "settlement": "Waknaghat, Solan", "region": "HP", "country": "India"}}, "email": "singhvaishnavi99@gmail.com"}, {"first": "Mohammad", "middle": [], "last": "Khubeb Siddiqui", "suffix": "", "affiliation": {"laboratory": "", "institution": "Tecnologico de Monterrey", "location": {"settlement": "Monterrey", "region": "N.L", "country": "Mexico"}}, "email": ""}]}, "abstract": [{"text": "The world is suffering from an existential global health crisis known as the COVID-19 pandemic. Countries like India, Bangladesh, and other developing countries are still having a slow pace in the detection of COVID-19 cases. Therefore, there is an urgent need for fast detection with clear visualization of infection is required using which a suspected patient of COVID-19 could be saved. Therefore, there is an urgent need for fast detection and clear visualization of infection is required. In the recent technological advancements, the fusion of deep learning classifiers and medical images provides more promising results corresponding to traditional RT-PCR testing while making detection and predictions about COVID-19 cases with increased accuracy. In this paper, we have proposed a deep transfer learning algorithm that accelerates the detection of COVID-19 cases by using X-ray and CT-Scan images of the chest. It is because, in COVID-19, initial screening of chest X-ray (CXR) may provide significant information in the detection of suspected COVID-19 cases. We have considered three datasets known as 1) COVID-chest X-ray, 2) SARS-COV-2 CT-scan, and 3) Chest X-Ray Images (Pneumonia). In the obtained results, the proposed deep learning model can detect the COVID-19 positive cases in \u2264 2 seconds which is faster than * Corresponding author RT-PCR tests currently being used for detection of COVID-19 cases. We have also established a relationship between COVID-19 patients along with the Pneumonia patients which explores the pattern between Pneumonia and COVID-19 radiology images. In all the experiments, we have used the Grad-CAM based color visualization approach in order to clearly interpretate the detection of radiology images and taking further course of action. dataset distribution is 232, 72, and 60 for training, validation, and testing 375 purposes respectively. Once the dataset has been classified, we can apply the 376 proposed deep learning model using Algorithm 1 on the distributed dataset.", "cite_spans": [], "ref_spans": [], "section": "Abstract"}, {"text": "The training accuracy, validation accuracy, training loss, and validation 378 loss graphs are shown in the Fig. 9 . As represented by a red dot on curve line 379", "cite_spans": [], "ref_spans": [{"start": 107, "end": 113, "text": "Fig. 9", "ref_id": null}], "section": "Abstract"}], "body_text": [{"text": "1 Two frailties affect human beings greatly i.e., ill-health and economic 2 slowdown. Unfortunately, this novel coronavirus has brought them to the fore. 3 As we know, the COVID-19 virus targets the lungs of a suspected patient 4 and mutates there promptly. In such a scenario, the infected lungs become 5 inflamed and get filled with fluid. If we perform CT-Scan or X-ray imaging 6 of an infected person then the obtained results show shadowy patches in the 7 lungs called Ground Glass Opacity [1] . Due to the communicable nature, its 8 spread rate is much higher than its prediction or detection rate. 9 During the various experimental findings performed in this paper, it is 10 revealed that the condition of lungs infected with COVID-19 often relates to 11 another common lung infection known as Pneumonia. Usually, pneumonia is 12 an infection caused by either a virus, bacteria, or fungi. Similar to 13 pneumonia can also be life-threatening for the age group below 2 and people 14 above 65. It is contagious just like COVID-19 with several similar symptoms. 15 However, COVID-19 has proved itself to be more fatal than Pneumonia, as it 16 can lead on to cause Acute Respiratory Distress Syndrome (ARDS). In other 17 words, we can say that it happens as a result of progressing Pneumonia in 18 the lungs. 19 In the absence of an intelligent diagnosis method, there is a great re-20 quirement for fast and accurate detection of COVID-19 suspected patients. 21 However, the contemporary techniques available for the detection of this raging The main contributions of the paper are listed here:", "cite_spans": [{"start": 154, "end": 155, "text": "3", "ref_id": null}, {"start": 228, "end": 229, "text": "4", "ref_id": null}, {"start": 381, "end": 382, "text": "6", "ref_id": null}, {"start": 495, "end": 498, "text": "[1]", "ref_id": null}, {"start": 605, "end": 606, "text": "9", "ref_id": null}, {"start": 679, "end": 681, "text": "10", "ref_id": "BIBREF14"}, {"start": 759, "end": 761, "text": "11", "ref_id": null}, {"start": 834, "end": 836, "text": "12", "ref_id": "BIBREF17"}, {"start": 907, "end": 909, "text": "13", "ref_id": null}, {"start": 1066, "end": 1068, "text": "15", "ref_id": null}, {"start": 1144, "end": 1146, "text": "16", "ref_id": null}, {"start": 1312, "end": 1314, "text": "19", "ref_id": "BIBREF27"}, {"start": 1463, "end": 1465, "text": "21", "ref_id": null}], "ref_spans": [], "section": "Introduction"}, {"text": "\u2022 We have proposed a new deep transfer learning algorithm and tested it 77 on three different radiology datasets for faster detection of COVID-19.", "cite_spans": [], "ref_spans": [], "section": "76"}, {"text": "\u2022 With the usage of deep learning and its advantage, it is assumed that 79 proposed model is faster than the traditionally used RT-PCR testing 80 kit.", "cite_spans": [], "ref_spans": [], "section": "78"}, {"text": "\u2022 We also discover through the experimental by our proposed algorithm 82 that there is strong relevance between Pulmonary diseases like Pneumo-83 nia and COVID-19.", "cite_spans": [], "ref_spans": [], "section": "81"}, {"text": "\u2022 Grad-CAM analysis has been performed over obtained results provide 85 the coloured visualization of the regions of lungs infected by the COVID- 86 19 in both CT-scan and X-ray images.", "cite_spans": [{"start": 146, "end": 148, "text": "86", "ref_id": null}], "ref_spans": [], "section": "84"}, {"text": "\u2022 We also make the usage of false positive cases e.g., Pneumonia and 88 consider them in COVID-19 suspected category.", "cite_spans": [], "ref_spans": [], "section": "87"}, {"text": "\u2022 Efficacy of proposed model is more accurate on CT-scan compare to 90 CXR images. ", "cite_spans": [], "ref_spans": [], "section": "89"}, {"text": "where z [1] is the current layer, a [0] is the first or input layer, W [1] represents 187 the weights for the first layer and b [1] is the bias. For VGG19 Conv Layer [24], c . The final layer is shown in Eq. 3.", "cite_spans": [{"start": 8, "end": 11, "text": "[1]", "ref_id": null}, {"start": 71, "end": 74, "text": "[1]", "ref_id": null}, {"start": 128, "end": 131, "text": "[1]", "ref_id": null}], "ref_spans": [], "section": "89"}, {"text": "Or,", "cite_spans": [], "ref_spans": [], "section": "89"}, {"text": "Where i, j and k corresponds to row, column and channel for z [1] respec- it was able to achieve 75.2% top-1 and 92.5% top-5 accuracy. Therefore, we 247 have considered it as one of the base models for the proposed study. Here, the last 5 layers include an Average Pooling 2D layer which also 262 results in dimension reduction by reckoning the average values of each region.", "cite_spans": [{"start": 62, "end": 65, "text": "[1]", "ref_id": null}, {"start": 149, "end": 152, "text": "247", "ref_id": null}], "ref_spans": [], "section": "89"}, {"text": "The average pooling layer is followed by a flatten layer that creates a single ", "cite_spans": [], "ref_spans": [], "section": "263"}, {"text": "For evaluating the model we have calculated the precision, recall, F-284 measure score and accuracy using the confusion matrix as shown in Table 5 . where n represents the n th class. As, we have considered the binary image 315 classification therefore the value of class will be n = 2. For this, Here, we can 316 select any required datasets i.e \u03b4 1 or \u03b4 2 to the input variables in Algorithm 1.", "cite_spans": [], "ref_spans": [{"start": 139, "end": 146, "text": "Table 5", "ref_id": "TABREF4"}], "section": "283"}, {"text": "However, for multiclass image classification the value of n should be \u2265 2 .", "cite_spans": [], "ref_spans": [], "section": "317"}, {"text": "The main steps of the proposed algorithm are as follows: hyper-parameters as shown in Table 1 using which the best accuracy 337 for the proposed model has been obtained. ", "cite_spans": [], "ref_spans": [{"start": 86, "end": 93, "text": "Table 1", "ref_id": "TABREF0"}], "section": "318"}, {"text": "where, y denotes the true value, and p denotes the probability predicted 352 by model. Fig. 8(a) . The primary dataset is divided into three sub-368 datasets i.e. training, validation, and testing sets. In train and test split, 369 we have used 80% of images for training, and the remaining 20% for testing Fig. 10(a) and 10(b) . The recall, precision, and F1-score are also 393 mentioned in the Table 5 . From Table 5 , we can find that proposed model has The count of images of Pneumonia and COVID-19 are highlighted in 399 Fig. 8(b) . The objective of this experiment is explore the relationship between Here, values obtained after Experiment-2 for training accuracy, validating These results are shown in Fig. 10 (c) and 10(d). Here, we can find the clear Through the confusion matrix presented in Table 4 ", "cite_spans": [{"start": 228, "end": 231, "text": "369", "ref_id": null}], "ref_spans": [{"start": 87, "end": 96, "text": "Fig. 8(a)", "ref_id": "FIGREF29"}, {"start": 307, "end": 327, "text": "Fig. 10(a) and 10(b)", "ref_id": "FIGREF31"}, {"start": 396, "end": 403, "text": "Table 5", "ref_id": "TABREF4"}, {"start": 411, "end": 418, "text": "Table 5", "ref_id": "TABREF4"}, {"start": 526, "end": 535, "text": "Fig. 8(b)", "ref_id": "FIGREF29"}, {"start": 709, "end": 716, "text": "Fig. 10", "ref_id": "FIGREF31"}, {"start": 802, "end": 809, "text": "Table 4", "ref_id": null}], "section": "318"}], "bib_entries": {"BIBREF1": {"ref_id": "b1", "title": "Early ct features and temporal lung changes in covid-19 pneumonia in 473 wuhan, china", "authors": [], "year": 2020, "venue": "European Journal of Radiology", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF3": {"ref_id": "b3", "title": "Deep learning in medical image analysis", "authors": [{"first": "D", "middle": [], "last": "Shen", "suffix": ""}, {"first": "G", "middle": [], "last": "Wu", "suffix": ""}, {"first": "H.-I", "middle": [], "last": "Suk", "suffix": ""}], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF5": {"ref_id": "b5", "title": "Coronavirus pandemic: A predictive analysis of 481 the peak outbreak epidemic in South Africa, Turkey, and Brazil", "authors": [{"first": "S", "middle": [], "last": "Djilali", "suffix": ""}, {"first": "B", "middle": [], "last": "Ghanbari", "suffix": ""}], "year": null, "venue": "Chaos", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF7": {"ref_id": "b7", "title": "Role of intelligent computing in covid-19 prognosis: 484 A state-of-the-art review", "authors": [{"first": "S", "middle": [], "last": "Hanumanthu", "suffix": ""}], "year": 2020, "venue": "Chaos, Solitons & Fractals", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF8": {"ref_id": "b8", "title": "Hus-486 sain, K. Khatoon, S. Ahmad, Correlation between temperature and 487 covid-19 (suspected, confirmed and death) cases based on machine learn-488 ing analysis", "authors": [{"first": "M", "middle": ["K"], "last": "Siddiqui", "suffix": ""}, {"first": "R", "middle": [], "last": "Morales-Menendez", "suffix": ""}, {"first": "P", "middle": ["K"], "last": "Gupta", "suffix": ""}, {"first": "H", "middle": ["M"], "last": "Iqbal", "suffix": ""}, {"first": "F", "middle": [], "last": "", "suffix": ""}], "year": 2020, "venue": "J. Pure Appl. Microbiol", "volume": "14", "issn": "", "pages": "", "other_ids": {}}, "BIBREF10": {"ref_id": "b10", "title": "Deep learning system to screen coronavirus disease 2019 491 pneumonia", "authors": [{"first": "G", "middle": [], "last": "Lang", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2002.09334"]}}, "BIBREF12": {"ref_id": "b12", "title": "Rapid ai development cycle for the 494 coronavirus (covid-19) pandemic: Initial results for automated detection 495 & patient monitoring using deep learning ct image analysis", "authors": [{"first": "W", "middle": [], "last": "Ji", "suffix": ""}, {"first": "A", "middle": [], "last": "Bernheim", "suffix": ""}, {"first": "E", "middle": [], "last": "Siegel", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.05037"]}}, "BIBREF13": {"ref_id": "b13", "title": "Analysis and forecast of covid-19 spreading in 498 china, italy and france", "authors": [{"first": "D", "middle": [], "last": "Fanelli", "suffix": ""}, {"first": "F", "middle": [], "last": "Piazza", "suffix": ""}], "year": 2020, "venue": "Chaos, Solitons & Fractals", "volume": "134", "issn": "", "pages": "", "other_ids": {}}, "BIBREF14": {"ref_id": "b14", "title": "Finding covid-19 500 from chest x-rays using deep learning on a small dataset", "authors": [{"first": "L", "middle": ["O"], "last": "Hall", "suffix": ""}, {"first": "R", "middle": [], "last": "Paul", "suffix": ""}, {"first": "D", "middle": ["B"], "last": "Goldgof", "suffix": ""}, {"first": "G", "middle": ["M"], "last": "Goldgof", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2004.02060"]}}, "BIBREF16": {"ref_id": "b16", "title": "Artificial intelligence and machine learning to fight covid-19", "authors": [], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF17": {"ref_id": "b17", "title": "Deep learning system to screen 505 coronavirus disease 2019 pneumonia", "authors": [{"first": "C", "middle": [], "last": "Butt", "suffix": ""}, {"first": "J", "middle": [], "last": "Gill", "suffix": ""}, {"first": "D", "middle": [], "last": "Chun", "suffix": ""}, {"first": "B", "middle": ["A"], "last": "Babu", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF19": {"ref_id": "b19", "title": "Application of Deep Learning for Fast detection of COVID-19 in X-rays 508 using nCOVnet", "authors": [], "year": 2020, "venue": "Chaos, Solitons & Fractals", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF20": {"ref_id": "b20", "title": "Deep transfer learning-based covid-19 510 prediction using chest x-rays, medRxiv", "authors": [{"first": "S", "middle": [], "last": "Kumar", "suffix": ""}, {"first": "S", "middle": [], "last": "Mishra", "suffix": ""}, {"first": "S", "middle": ["K"], "last": "Singh", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF22": {"ref_id": "b22", "title": "A transfer learning method for pneumonia classification and 513 visualization", "authors": [{"first": "", "middle": [], "last": "Nieto", "suffix": ""}], "year": 2020, "venue": "Applied Sciences", "volume": "10", "issn": "", "pages": "", "other_ids": {}}, "BIBREF23": {"ref_id": "b23", "title": "Covid-19: automatic detection 515 from x-ray images utilizing transfer learning with convolutional neural 516 networks", "authors": [{"first": "I", "middle": ["D"], "last": "Apostolopoulos", "suffix": ""}, {"first": "T", "middle": ["A"], "last": "Mpesiana", "suffix": ""}], "year": 2020, "venue": "Physical and Engineering Sciences in Medicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF24": {"ref_id": "b24", "title": "Covid-19 detection using deep learning 518 models to exploit social mimic optimization and structured chest x-ray 519 images using fuzzy color and stacking approaches", "authors": [{"first": "M", "middle": [], "last": "Toga\u00e7ar", "suffix": ""}, {"first": "B", "middle": [], "last": "Ergen", "suffix": ""}, {"first": "Z", "middle": [], "last": "C\u00f6mert", "suffix": ""}], "year": 2020, "venue": "Computers in Biology", "volume": "520", "issn": "", "pages": "", "other_ids": {}}, "BIBREF26": {"ref_id": "b26", "title": "Automated detection of COVID-19 cases using deep neural 523 networks with x-ray images", "authors": [{"first": "", "middle": [], "last": "Acharya", "suffix": ""}], "year": 2020, "venue": "Computers in Biology and Medicine", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF27": {"ref_id": "b27", "title": "Covid-19 image data collection", "authors": [{"first": "J", "middle": ["P"], "last": "Cohen", "suffix": ""}, {"first": "P", "middle": [], "last": "Morrison", "suffix": ""}, {"first": "L", "middle": [], "last": "Dao", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:2003.11597"]}}, "BIBREF29": {"ref_id": "b29", "title": "CT-scan dataset: A large dataset of real patients CT scans for SARS-529", "authors": [], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF30": {"ref_id": "b30", "title": "CoV-2 identification, medRxiv", "authors": [], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF31": {"ref_id": "b31", "title": "Labeled Optical Coherence Tomog-531 raphy (OCT) and Chest X-Ray Images for Classification", "authors": [{"first": "D", "middle": [], "last": "Kermany", "suffix": ""}, {"first": "K", "middle": [], "last": "Zhang", "suffix": ""}, {"first": "M", "middle": [], "last": "Goldbaum", "suffix": ""}], "year": 2018, "venue": "Mendeley data", "volume": "532", "issn": "2", "pages": "", "other_ids": {"DOI": ["10.17632/rscbjbr9sj.2"]}}, "BIBREF32": {"ref_id": "b32", "title": "Chest X-Ray Images (Pneumonia)", "authors": [{"first": "P", "middle": [], "last": "Mooney", "suffix": ""}], "year": 2020, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF33": {"ref_id": "b33", "title": "Deep learning", "authors": [{"first": "I", "middle": [], "last": "Goodfellow", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}, {"first": "A", "middle": [], "last": "Courville", "suffix": ""}], "year": 2016, "venue": "", "volume": "538", "issn": "", "pages": "", "other_ids": {}}, "BIBREF34": {"ref_id": "b34", "title": "Very Deep Convolutional Networks for 540", "authors": [{"first": "K", "middle": [], "last": "Simonyan", "suffix": ""}, {"first": "A", "middle": [], "last": "Zisserman", "suffix": ""}], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF35": {"ref_id": "b35", "title": "Large-Scale Image Recognition", "authors": [], "year": 2015, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1409.1556"]}}, "BIBREF36": {"ref_id": "b36", "title": "Convolutional Net-543 works", "authors": [{"first": "I", "middle": [], "last": "Goodfellow", "suffix": ""}, {"first": "Y", "middle": [], "last": "Bengio", "suffix": ""}, {"first": "A", "middle": [], "last": "Courville", "suffix": ""}], "year": 2016, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF38": {"ref_id": "b38", "title": "An introduction to convolutional neural networks", "authors": [{"first": "K", "middle": [], "last": "Shea", "suffix": ""}, {"first": "R", "middle": [], "last": "Nash", "suffix": ""}], "year": 2015, "venue": "", "volume": "547", "issn": "", "pages": "", "other_ids": {"arXiv": ["arXiv:1511.08458"]}}, "BIBREF40": {"ref_id": "b40", "title": "Visual explanations from deep networks via gradient-based 550 localization", "authors": [{"first": "", "middle": [], "last": "Grad-Cam", "suffix": ""}], "year": 2017, "venue": "", "volume": "", "issn": "", "pages": "618--626", "other_ids": {}}, "BIBREF41": {"ref_id": "b41", "title": "Analyzing performance of 553 classification techniques in detecting epileptic seizure", "authors": [{"first": "M", "middle": ["K"], "last": "Siddiqui", "suffix": ""}, {"first": "M", "middle": ["Z"], "last": "Islam", "suffix": ""}, {"first": "M", "middle": ["A"], "last": "Kabir", "suffix": ""}], "year": null, "venue": "", "volume": "", "issn": "", "pages": "", "other_ids": {}}, "BIBREF42": {"ref_id": "b42", "title": "Conference on Advanced Data Mining and Applications", "authors": [], "year": 2017, "venue": "", "volume": "555", "issn": "", "pages": "386--398", "other_ids": {}}}, "ref_entries": {"FIGREF0": {"text": "22 pandemic are moderately accurate and costs a range of time. Currently, there 23 are three different types of COVID-19 testing mechanisms known as Reverse 24 Transcription Polymerase Chain Reaction (RT-PCR), Computed Tomography 25 (CT) Scan, and Chest X-Ray (CXR). Among these three, RT-PCR is one of 26 the time-consuming techniques whereas, CXR can detect inflammation in the 27 lungs along with its position, shape, and size, and CT-Scan is a more effective 28 way to diagnose COVID-19 and Pneumonia as it provides a detailed picture 29 of air sacs. Therefore, in our various experimentations we have selected CXR 30 and CT-Scan images of lungs.31 1.1. Role of Deep Learning in Detection/Prediction 32 Healthcare providers generate and capture enormous amounts of data 33 containing extremely valuable signals and information, at a pace far surpassing 34 what traditional methods of analysis can process. As we know, the RT-PCR 35 test is one of the time-consuming and costly methods used for the detection 36 of COVID-19 suspects. Therefore, it is necessary to look for the optimum 37 solution in which fusion of deep learning classifiers and medical images provide 38 the fast and accurate detection of the COVID-19 virus during the analyses 39 of CXR and CT-Scan images of lungs. In this paper, the proposed method 40 can directly help radiologists for fast detection of COVID-19 which in-turn 41 improves the overall detection time and accuracy rate in CXR and CT-Scan 42 images. 43 Deep Learning (DL) is a subset of Machine Learning (ML) that enables 44 computers for automatic training or learning of sensible features from data [2]. 45 In medical imaging, most of the deep learning breakthrough has happened 46 with the introduction of the convolutional neural network (CNN). It is because, Deep Models such as Stacked Auto-Encoder (SAE), Deep Belief Network 48 (DBN), and Deep Boltzmann Machine (DBM) always have inputs in the 49 form of a vector [3]. However, in medical imaging, vectorization destroys the 50 structural and configurational information available in the neighbouring pixels 51 and voxels is one of the important structural information. CNN considers 52 the input in the form of 2D or 3D images and can better utilize spatial and 53 configurational information [3]. 54 Infection on lungs is one of the major signs of COVID-19 and Pneumonia. 55 Which can be seen while examining the CXR and CT-Scan images of lungs 56 and could provide a breakthrough during diagnosing COVID-19. Therefore, 57 we have considered the use of deep learning classifiers and proposed a novel 58 algorithm for extracting the features from various radiology images to detect 59 the presence of infection. The proposed algorithm ensures the use of deep 60 transfer learning on CXR and CT-Scan images of lungs and assesses the 61 report of suspected COVID-19 patients.", "latex": null, "type": "figure"}, "FIGREF1": {"text": "In this paper, we have considered the advantage of deep learning classifiers63 for extracting the features from the taken radiology images of COVID-19 such 64 as CXR and CT Scan and trained them against a combination of Pneumonia, 65 other pulmonary diseases and normal cases. The detection made by our 66 model are visualised by plotting class activation maps using Grad-CAM 67 technique. Thus, our model can be used both independently and alongside a 68 radiologist. The model also focuses on the False Positives (FP) due to the 69 patients with Pneumonia which can create a chaotic scenario. Considering a 70 patient having Pneumonia who is detected falsely by our model as COVID-19 71 positive will be asked to be admitted in a suspected COVID-19 section of 72 the hospital. Through our experiments it has been suggested to consider the 73 Pneumonia cases in suspected category in order to prevent the further spread 74 of COVID-19.", "latex": null, "type": "figure"}, "FIGREF3": {"text": "We used the concept of 'early stopping' in our proposed model in order 92 to overcome the overfitting issue and perform better in real-time. 93 This paper is further organized into various sections where section 2 sum-94 marizes the various studies on detection of COVID-19 using deep learning 95 approaches. Section 4 discusses about applied datasets, deep learning techniques, and performance evaluation criteria. Section 5 presents the proposed 97 algorithm for fast detection of COVID-19 using binary classification.Section 6 98 presents the experimental analysis and their outcomes. Finally, section 7 99 concludes this paper.", "latex": null, "type": "figure"}, "FIGREF4": {"text": "AI), deep learning, and machine learning techniques. Recently, deep learning 105 techniques have been widely considered for resolving many healthcare-related 106 issues and the deep learning techniques have proved themselves to be effec-107 tive in providing significant results. Data scientists have been focusing on 108 improving the detection, analysis, and further prediction of various diseases 109 by taking radiology datasets and apply data science classifiers.", "latex": null, "type": "figure"}, "FIGREF5": {"text": "Panwar et al. [13] have proposed the algorithm nCOVnet based on the data 111 leakage concept for fast detection of the COVID-19 cases. In their experiments 112 obtained detection accuracy is 88%, here authors did not provided the clear 113 visualization of detected COVID-19 cases on the CXR images. Kumar et al. 114 [14] have proposed a model called DeQueezeNet which classify the patients 115 X-ray images into two categories positive and negative while detecting the 116 COVID-19. The proposed model predicts the possibility of the disease with 117 94.52% accuracy with the precision of 90.48%, by pre-processing the X-ray 118 images of positive COVID-19 patients and normal cases. Transfer learning 119 has achieved brilliant results in the field of image classification tasks. Luj\u00e1n-120 Garc\u00eda et al. [15], have used chest X-rays for the detection of Pneumonia 121 and further classification between patients infected with Pneumonia or not. 122 The proposed model considers the 36 convolutional layers and has obtained 123 0.843 precision score. Apostolopoulos and Mpesiana [16] have presented the 124 implementation of transfer learning in COVID-19 detection as there is a 125 very limited amount of data available. They have obtained an accuracy 126 of 96.78%. However, experiments reveal that the dataset was not much 127 balanced. Therefore, feature extraction and classification have turned out to 128 be effective by using transfer learning, In another related work, Toga\u00e7ar et al.", "latex": null, "type": "figure"}, "FIGREF6": {"text": "17] have considered the chest X-ray images for three different class values 130 known as COVID-19, Pneumonia and normal to reduce the noise by fuzzy 131 technique and stacking. They have considered the SqueezeNet as a model 132 and comprehended the accuracy with varying levels of reconstructed datasets 133 and provided significant accuracy in their obtained results. However, one 134 of the setbacks of this model is that it is not able to work much efficiently 135 with low-resolution images. In Ozturk et al. [18], have presented another 136 advancement for classification of COVID-19 by proposing a model for binary 137 as well as for the multi-class classification of diseases like COVID-19, regular 138 Pneumonia, and no-findings of any of them. They achieved a 98.08% of 139 accuracy in binary classification and 87.02% accuracy in multi-class along 140 with 17 convolutional layers.", "latex": null, "type": "figure"}, "FIGREF7": {"text": "such as AI, Data Science, Machine Learning, and 143 data mining are being used actively to obtain the effective solution of COVID-144 19 pandemic. These methods are mainly dependent on the datasets for making 145 an effective detection. Since COVID-19 is a new disease therefore the limited 146 amount of dataset is available for the execution of experiments. However, to 147 apply deep learning on radiology imaging, few public datasets are available. 148 Dataset by Cohen et al. [19] is one of the most used data set for performing 149 experiments related to COVID-19. In this work, we have considered the 150 following three datasets for the execution of different experiments. 151 \u2022 COVID-chest X-ray-dataset -Cohen et al. [19] have compiled this 152 dataset and is being used widely by many researchers. The recent 153 updated images are timely included in the database. We collected this 154 dataset on 09th Jun, 2020 which consist of 673 radiology images of 342 155 unique patients. These radiology images includes various CXR and 156 CT-scans of COVID-19 infected patients and with other pulmonary 157 diseases too. After selecting the unique cases of COVID-19 positive 158 patients the total number of patients reduces to 285 along with total 159 number of images to 526. The CXR images available in this dataset can 160 be categorized into three different categories known as Posteroanterior 161 (PA), Anteroposterior (AP), and AP Supine (APS). In experiments, we 162 have used the PA view as it provides the better view of the lungs.", "latex": null, "type": "figure"}, "FIGREF8": {"text": "Use of this dataset ensures the issue of data leakage as there are different 164 unique patients, having more than one sample of CXR or CT-Scan 165 images available in the datasets. Therefore, while splitting the dataset 166 for training and testing purpose, we have also addressed the issue of data leakage, then a single patients CXRs or CT-Scans could end up in 168 both testing and training giving false results. 169 \u2022 SARS-COV-2 CT-scan -Soares et al. [20] have compiled this publicly 170 available dataset. This dataset is collected from a hospital in Sao Paulo, 171 Brazil and approved by their ethical committee. It consists of 1252 172 CT-Scans of COVID-19 positive patients and 1230 CT-Scans for NON-173 COVID patients which are COVID-19 negative but may have other 174 pulmonary diseases. Chest X-ray Images (Pneumonia)-Kermany et al. [21] have created 176 this dataset. This dataset has large number of publicly available OCT 177 and CXR images. In the experiments, we have used the X-Rays part of 178 this dataset which consists of 5856 images of Pneumonia and Normal 179 patients [22].", "latex": null, "type": "figure"}, "FIGREF9": {"text": "CNNs) and Transfer Learning. The CNNs are very much similar to vanilla 183 Neural Networks except convolution operations which take place in one or 184 more than one layer of CNN [23]. A simple neural network's layer is presented 185 in Eq. 1.", "latex": null, "type": "figure"}, "FIGREF11": {"text": "we have changed the multiplication operation with the convolution operation 189 and updated the weights of a 2-D weight matrix to a 3-D filter tensor. In 190 Eq. 2 each channel of x, there is a corresponding channel in the first filter of", "latex": null, "type": "figure"}, "FIGREF12": {"text": "tively and represents the final product. Whereas l, m, n is the row, column and 195 channel number of the filter respectively, and k is the symbol which reflects 196 the filter currently being used. Notice how the convolution operation in Eq. 2 197 becomes just like matrix multiplication in Eq. 3. As shown in Eq. 2 andFig. 2, 198the convolution operation generally marked by the (*) sign, here its working 199 is different from mathematics/statistics perspective[23, 25]. Technically, it is200 one of the related function known as cross-correlation but many times in the 201 deep learning literature it is confused with the word convolution. A basic CNN architecture for the binary classification of COVID-19 images", "latex": null, "type": "figure"}, "FIGREF13": {"text": "consists of input, convolution, pooling, fully connected, and output 203 layers. In the input layer, the type of data is CXR or CT-Scan images.204 Whereas, Fig. 2 separately presents the convolution layer, pooling layer, and 205 connected layer. Fig.2 also discusses the sample of the convolution operation 206 on 6 \u00d7 6 matrix using a 3\u00d73 filter and a stride of 2. The movement of the 207 filter window on the input matrix is defined by using a stride value. After the 208 convolutional layer, the next layer is a pooling layer which is used to reduce 209 the computational loss of the network. Some popular pooling functions such 210 as average, L2 norm, minimum, and maximum pooling are considered here. 211 An example of maxpooling operation is shown in Fig. 3. Further, next to the A sample of the convolution operation with filter size =3, and stride = A sample of maxpooling operation with 2x2 window size pooling layer is fully connected layer, in which each neuron in fully connected 213 to each neuron of the flattened version of the previous layer and shown in , the obtained output depends on the classes used to train the 216 proposed model. In this work, we have classified the output into four different 217 classes which can be recognised as follows: 218 \u2022 COVID-19: states the identified COVID-19 positive cases by examin-219 ing the CXR and CT-Scan images. Pneumonia: states the identified CXR images of patients that consist 221 the patches of Pneumonia infection. Non-COVID-19 includes the radiology images of the patients which 223 are found negative to COVID-19 tests. However, as per descriptions 224 provided for the concerned dataset these patients may have other pul-A sample of the flattening operation \u2022 Normal: Includes the radiology images of various cases which are 227 neutral or negative to COVID-19, Pneumonia and other pulmonary 228 infections.", "latex": null, "type": "figure"}, "FIGREF14": {"text": "Proposed Transfer learning Model with Five Extra Layers 230 In this section, we have focused on the problem of binary classification 231 of images with a finite amount of dataset. For addressing the challenges in 232 COVID-19 detection, transfer learning is one of the most considerable methods 233 used for classification of images. In transfer learning, the method of applying 234 the expertise or knowledge is gained from one task to execute another kindred 235 piece of work. The idea turns out to be prominent when working with a 236 limited dataset for the training of the proposed model. We have used VGG-19 237 as one of the transfer learning techniques as the available dataset of radiology 238 imaging relates to X-rays of COVID-19 patients is limited. In VGG-19, there 239 are 19-weighted layers of deep convolutional neural network using which a 240 comparably outperforming classification accuracy can be achieved. Among 241 these 19-weighted layers, there are 16-convolution layers, and 3-fully connected 242 layers. Here, the proposed model also consists of 5-MaxPool layers and a 243 1-softmax layer with all hidden layers having rectification non-linearity [24]. 244 The VGG19 model is further trained on ImageNet [26] consisting a big dataset 245 of 14197122 images which is categorized into thousands of classes on which 246", "latex": null, "type": "figure"}, "FIGREF15": {"text": "Model summary with VGG19 as base model and last 5 layes as head model The proposed model consists of 27 layers in which the first layer is the input 249 layer of size 512 \u00d7 512 \u00d7 3 pixels. Fig. 6 highlights the architecture consisting 250 of an input layer followed by a set of 19-weighted layers accommodating 251 a union of convolutional layers with rectification non-linearity applied and 252 max-pooling layer. In the convolutional layers, filters of size 3 \u00d7 3 consisting 253 of the most user-defined parameters, has been applied to the image. All 254 the Max pooling layers perform the function of obtaining a maximum value 255 in a certain filter patch and result in a reduction of its dimensionality. In 256 VGG-19, Max-Pooling has been performed over a 2 \u00d7 2 pixel window with 257 stride=2 [27]. Here, the fully connected layers are the final set of layers used 258 for flattening the results before the classification of images. Finally, The final 259 layer in this set is the softmax layer which is responsible for the network to 260 run a multi-class function.", "latex": null, "type": "figure"}, "FIGREF16": {"text": "The Network configuration of VGG19 model for COVID-19", "latex": null, "type": "figure"}, "FIGREF17": {"text": "264 feature vector, i.e, it removes all the dimensions except one, in a matrix of 265 features. The single feature vector is then put into a dense layer of 64 units 266 in size. A dropout layer is then applied with a threshold of 0.5, which drops 267 some units to prevent the model from overfitting.", "latex": null, "type": "figure"}, "FIGREF18": {"text": "of work is being done to make deep learning more sensible and 270 explainable. In various deep learning applications related to medical imaging, 271 it is very important to make the deep learning model more interpretative. Mapping (Grad-CAM) technique which provides the explainable view of deep 274 learning models. Grad-CAM technique creates the visual explanation for any 275 deeply connected Neural Network and helps in determining more about the 276 model while performing detection or prediction work. A simple explanatory diagram of Gradient Weighted Class Activation Mapping (Grad-CAM)As presented in theFig. 7, the Grad-CAM takes a simple image as input278    and detection techniques are applied further by using the proposed model.", "latex": null, "type": "figure"}, "FIGREF19": {"text": "Once the predicted label has been calculated using the full model, Grad-CAM 280 is applied to any of the Conv layers. Mostly, the last Conv layer is considered 281 as the layer to be used for applying Grad-CAM.", "latex": null, "type": "figure"}, "FIGREF21": {"text": "These have been calculated by following parameter and equations [29]: 286 1. True Positive (TP): If a COVID-19 infected person is detected as 287 COVID-19.", "latex": null, "type": "figure"}, "FIGREF22": {"text": "True Negative (TN): If a person is correctly detected as NON-289 COVID-19.", "latex": null, "type": "figure"}, "FIGREF23": {"text": "False Positive (FP): represents incorrect detection where a normal 291 person is detected positive for COVID-19.", "latex": null, "type": "figure"}, "FIGREF24": {"text": "False Negative (FN): represents incorrect detection where a person 293 infected with COVID-19 is detected as normal one.", "latex": null, "type": "figure"}, "FIGREF25": {"text": "Precision calculates the fraction of correct positive detection of COVID-Recall gives how good are all the positives which depends on the 299 percentage of total relevant cases correctly classified by the model. F-Measure is a harmonic mean between precision and recall. proposed deep transfer learning algorithm mainly focuses on binary 305 classification of images in order to classify the various CXR and CT-Scan 306 images for fast and accurate detection of COVID-19. The proposed algorithm 307 considers the pre-trained weights to extract simple features and then learn 308 the pattern of COVID-19 cases obtained from the patients' CXR and CT-309 Scan images. The main feature of the proposed technique is that it is fully 310 connected layers with five extra layers in VGG-19 model. Similar to other 311 algorithms it also considers the input dataset. Here, CXR and CT-Scan 312 images which includes the cases of COVID-19, NON-COVID-19, Pneumonia and Normal, have been considered. The dataset is represented using \u03b4 n 314", "latex": null, "type": "figure"}, "FIGREF26": {"text": "Step1: Generate the train, validate, and test dataset-320 generates three required sub-datasets from the input dataset. Here, the 321 first sub-dataset is a training dataset in which the sample of data is 322 used to fit the model for learning purposes. In the second sub-dataset 323 of validation, a set of samples is considered to tune the various hyper-324 parameters for an unbiased evaluation of the classifier while selecting the 325 number of hidden units in a neural network. Finally, test sub-dataset 326 which is a random set of samples used to assess the performance of a 327 fully-specified model. The split ratio of training, validation, and testing 328 sub-dataset are considered 64, 20, and 16 respectively. Step2: Prepare the base model and the new model 330 In this step, we have used VGG-19 with pre-trained weights on ImageNet 331 as a base model. The proposed model has been trained for adapting 332 and learning the basic features (e.g., edges and boundaries) of computer 333 vision which ensures that the model needs not to learn every time from 334 scratch while training on CXR and CT-Scan image datasets. After 335 certain attempts of experimentation's we have explored the most suitable336", "latex": null, "type": "figure"}, "FIGREF27": {"text": "Step 3: Update and store the trained weights339    Finally, these weights have been used to detect COVID-19 cases. For-340 ward propagation does the calculation process and obtains the values 341 of the output layers from the inputs data. It traverses through all the 342 neurons and covers each layer from the beginning. The binary cross-343 entropy loss function is then calculated using Eq. 9 from the output 344 values. As the backpropagation occurs, it counts the number of changes 345 in the weights. The computation process begins from the last layer 346 onwards i.e starting from the backward layer to the first layer. Forward 347 and backward pass together contributes to one iteration. During this 348 one iteration, a subset of the data set is passed and depicted as per 349 batch size (BS) which is also known as one epoch and represents passing 350 of entire data set at once. 351 Cross Entropy = \u2212(ylog(p) + (1 \u2212 y)log(1 \u2212 p))", "latex": null, "type": "figure"}, "FIGREF28": {"text": "370purposes. However, for validation purpose we have used 20% of images from 371 the 80% of training images.", "latex": null, "type": "figure"}, "FIGREF29": {"text": "Frequency of each Class in the Dataset (a) Number of images in Normal (364) and COVID-19 (206) class, (b) Number of images in COVID-19 (206) and Pneumonia (364) class, (c) Number of images in COVID-19 (800) and Non COVID-19 (800) class. of training accuracy and validation accuracy, we have obtained the best results 380 for the proposed model on the 13 th epoch. The significance of the proposed 381 model is that it automatically avoids overfitting issue through early stopping 382 method. Therefore, it gets stopped at 29 th epoch as plotted in Fig. 9. The 383 performance of the proposed model has been calculated by using the confusion 384 matrix as shown in Table 2. Based on this, we have calculated the sensitivity 385 and specificity of the proposed model. The sensitivity and specificity of the 386 proposed model is 76.19%, and 97.22% respectively. From these results, we 387 can infer that any patient who visits the hospital and is COVID-19 Negative 388 (i.e., True Negatives) can be detected as Normal with very high accuracy 389 during the tests by using the CXR and CT-Scan images. The radiologist 390 further can apply color visualization approach using Grad-CAM for making 391 efficient and confident decision because of clear visibility of the images as 392 shown in", "latex": null, "type": "figure"}, "FIGREF30": {"text": "394achieved an overall accuracy of 89.47% along with better understanding of 395 the predictions of the deep learning model, by implementing the Grad-Training loss, Validation loss, Training accuracy, Validation accuracy and early stopping for experiment 1.", "latex": null, "type": "figure"}, "FIGREF31": {"text": "Visualisation on CXR of COVID-19 infected person using Grad-CAM on the trained model. (a) Original CXR for COVID-19 vs Normal (Experiment-1), (b) Class activation map for COVID-19 vs Normal (Experiment-1), (c) Original CXR for Pneumonia vs COVID-19 (Experiment-2), (d) Class activation map for Pneumonia vs COVID-19 (Experiment-2). [Notes: The high-intensity visuals (blue and green) reflects the area of interest to our model at the time of prediction] around 2-3 years ago i.e., much before the outbreak of COVID-19. Whereas, 403 for the COVID-19 positive patients, we have considered the same data as 404 provided in Experiment-1. The dataset split is performed in the same way as 405 it has been done for Experiment-1, and the final distribution is 231,85, and 406 48 for training, testing, and validation purposes respectively for Pneumonia 407 patients, and 133, 29, and 44 for training, testing, and validation purposes 408 respectively for COVID-19 positive patients. Algorithm 1 is further applied 409 to train the dataset on the proposed deep learning model.", "latex": null, "type": "figure"}, "FIGREF32": {"text": "Training loss, validation loss, training accuracy, validation accuracy and early stopping for experiment 2.", "latex": null, "type": "figure"}, "FIGREF33": {"text": "accuracy, training loss and validation loss are shown in the Fig. 11. This 412 indicates the training accuracy 97% after the first epoch only. However, 413 the best model with 100% training accuracy is achieved on the 6 th epoch and 414 the model gets stopped early on the 21 st epoch. to avoid ovefitting.415", "latex": null, "type": "figure"}, "FIGREF34": {"text": "patches in the chest CXR and CT-Scan images of COVID-19 positive cases.427 6.3. Experiment-3: COVID-vs Non-COVID 428 In this experiment, we have compared the results as obtained by CXR and 429 CT-Scan images for COVID-19 vs. Non-COVID-19 cases. For this, CT-scan 430 dataset of SARS-COV-2 is trained on the model for both COVID-19 and 431 NON-COVID-19 cases. Both the cases have equal number of images i.e., 800 432 as highlighted inFig. 8(c). The epochs vs loss/accuracy graph is shown in This indicates the best model has been obtained on the 33 rd epoch.434However, it gets stopped early at 47 th epoch to avoid any overfitting scenario. Training loss, validation loss, training accuracy, validation accuracy and early stopping for experiment 3.", "latex": null, "type": "figure"}, "FIGREF35": {"text": "The proposed model as trained in experiment 3, also provided distinguished 442 results when applied color visualization approach using Grad-CAM technique 443 and displayed the affected regions of lungs. These obtained results are shown 444 in Fig. 13(a) and 13(b). Once, the proposed model is trained on CT-Scan 445 images, the same can detect the COVID-19 patients successfully on random Visualisations of Experiment-3 for COVID-19 vs. Non-COVID-19 infected person using Grad-CAM on the trained model. (a) Original CT-Scan image, (b) Class activation map of original CT-Scan image, (c) Original CXR image, (d) Class activation map of original CXR image. [Notes: The high-intensity visuals (blue and green) reflects the area of interest to our model at the time of prediction] CXR images as shown in Fig. 13(c) and 13(d). SARS-COV-2 CT Scan dataset 447 is one of the most current dataset that has maximum number of COVID-19 448 and NON-COVID-19 radiology images [20].449", "latex": null, "type": "figure"}, "FIGREF36": {"text": "In this work, we have performed experiments on binary image classification 451 for the detection of COVID-19 and Non-COVID-19 positive patients. Further, 452 from the analysis, it is revealed that non-COVID-19 positive patients may 453 have Pneumonia or other pulmonary diseases. In various experiments for 454 detecting the COVID-19 cases, we have considered the CXR and CT-Scan 455 images of the chest. The proposed model provides an accuracy of 95.61% 456 while detecting the COVID-19 cases which is much faster than the traditional 457 RT-PCR testing approach. The weights obtained from the training of the 458 proposed model during the processing of CT Scan images also provide a 459 significant response to CXR images. In our experiments, we have also applied 460 a color visualization approach by using the Grad-CAM technique to make 461 the proposed deep learning model more interpretable and explainable. The 462 obtained results reveal that the patient diagnosed with Pneumonia has more 463 chances to get tested as a False Positive by the proposed algorithm. Therefore, 464 to detect the COVID-19 cases accurately with higher recall, it is suggested to 465 train the model on radiology images of patients with Pneumonia symptoms 466 as well. This will help us to detect pneumonia patients as True Negative 467 (just for clarification-here, COVID-19 cases are True Positive) which were 468 previously detected as false positive. This results in an unbiased detection of 469 COVID-19 cases in a real-time scenario. 470 P. Mal\u00edk, L. Hluch\u1ef3, Machine learning and deep learning frameworks and libraries for large-scale data mining: a survey, Artificial Intelligence", "latex": null, "type": "figure"}, "TABREF0": {"text": "Hyper-parameters values used in the experiments Initialize the hyperparameters: \u00b5, BS, 8. Train the CNN model and store the output weight (\u03c9). for = 1 to callback do Forward propagation and compute the binary cross-entropy loss. Backpropagation and update adam optimizer. end we have used 206 CXR images of COVID-19 infected patients from the COVID-chest X-ray-dataset [19] and 364 CXR images of Normal patients from the CXR Images (Pneumonia) dataset [21, 22], the count of the cases", "latex": null, "type": "table"}, "TABREF1": {"text": "Confusion Matrix for the experiment-1", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>Predicted Class\nCOVID-19 (Class-1) </td><td>Normal (class 2)\n</td></tr><tr><td>COVID-19 (Class-1) </td><td>TP = 32 </td><td>FN = 10\n</td></tr><tr><td>Actual Class\nNormal (class 2) </td><td>FP = 2 </td><td>TN = 70\n</td></tr></table></body></html>"}, "TABREF2": {"text": "Confusion Matrix for the experiment 2 Predicted Class COVID-19(Class 1) Pneumonia(class 2) From Table 3, we have calculated the performance parameters. Here, the obtained sensitivity is 96.55%, and the specificity is 95.29% for the positive cases of COVID-19. From the obtained results, we can infer that proposed model can detect COVID-19 patients (i.e. true positive) with 96.55% of accuracy. Further, the recall, precision and F-1 Score has been evaluated from the confusion Matrix as shown in Table 3. These calculated values are shown in Table 5. The overall accuracy of proposed model is 96.55% while detecting the COVID-19 cases correctly. For better understanding and presentation of finding the patches on the lungs, we have also implemented the color visualization approach on images by using Grad-CAM technique.", "latex": null, "type": "table"}, "TABREF3": {"text": ", sensitivity, and specificity values have been calculated, which are 94.04% and 95.86% respectively.From these results, we can claim that a COVID-19 patient can be tested accurately along with 94.04% accuracy. We have also observed that CT Scans are relatively more reliable to use in training our model as the CT Scans images provide a better and detailed description to the radiologist.", "latex": null, "type": "table"}, "TABREF4": {"text": "Evaluation of Binary Class Image Classification", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>Class-1 </td><td>\u00a0</td><td>Class-2 </td><td>\u00a0</td><td>Overall\n</td></tr><tr><td>Exp\n</td><td>\u00a0</td><td>\u00a0</td><td>F1\n</td><td>\u00a0</td><td>\u00a0</td><td>F1\n</td><td>Accuracy\n</td></tr><tr><td>Precision </td><td>Recall\n</td><td>Score\n</td><td>Precision </td><td>Recall\n</td><td>Score\n</td><td>\u00a0</td></tr><tr><td>Exp-1 </td><td>0.94 </td><td>0.76 </td><td>0.84 </td><td>0.88 </td><td>0.97 </td><td>0.92 </td><td>89.47%\n</td></tr><tr><td>Exp-2 </td><td>0.88 </td><td>0.97 </td><td>0.92 </td><td>0.99 </td><td>0.95 </td><td>0.97 </td><td>95.61%\n</td></tr><tr><td>Exp-3 </td><td>0.95 </td><td>0.94 </td><td>0.95 </td><td>0.95 </td><td>0.96 </td><td>0.95 </td><td>95%\n</td></tr></table></body></html>"}, "TABREF5": {"text": "Table 1: Hyper-parameters values used in the experiments", "latex": null, "type": "table", "html": "<html><body><table><tr><td>Hypermeters </td><td>Values\n</td></tr><tr><td>Batch Size </td><td>15 Samples\n</td></tr><tr><td>Train Validate Test Split ratio Optimizer </td><td>64:20:16\nAdam\n</td></tr><tr><td>Rotation range </td><td>15\n</td></tr><tr><td>Zoom range </td><td>0.05\n</td></tr><tr><td>Width shift range </td><td>0.1\n</td></tr><tr><td>Height shift range </td><td>0.1\n</td></tr><tr><td>Shear range </td><td>0.05\n</td></tr><tr><td>Input size </td><td>512*512 pixels\n</td></tr><tr><td>Dropout </td><td>0.5\n</td></tr></table></body></html>"}, "TABREF6": {"text": "Table 4: Confusion Matrix for the experiment 3", "latex": null, "type": "table", "html": "<html><body><table><tr><td>\u00a0</td><td>COVID-19(Class 1) </td><td>Predicted Class\nNon-COVID-19(class 2)\n</td></tr><tr><td>COVID-19(Class 1) </td><td>142 </td><td>9\n</td></tr><tr><td>Acutal Class\nNon-COVID-19(class 2) </td><td>7 </td><td>162\n</td></tr></table></body></html>"}}, "back_matter": []}